{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c9d13c-0e66-42c7-9d80-143b865ba127",
   "metadata": {},
   "source": [
    "# Dados externos IMDb\n",
    "\n",
    "O objetivo desse notebook é servir com um ETL para os dados externos do [IMDb](https://developer.imdb.com/non-commercial-datasets/).\n",
    "\n",
    "O output final será um `csv` que será salvo no S3 e posteriormente exportado para a máquina virtual que contém o restante da aplicação de forma local.\n",
    "\n",
    "Seguiremos os sequintes passos:\n",
    "\n",
    "1. Configurar os bucktes no S3 para salvar os dados de entrada, cache do Athena e dados de saída\n",
    "2. Baixar os dados do IMDb e salvar na landing zonde do S3\n",
    "3. Configurar o Glue para mapearmos os dados necessários\n",
    "4. Breve visualização dos dados utilizando pyathena\n",
    "5. Utilizar o pyathena para executar as queries necessárias e gerar o output final\n",
    "\n",
    "Faremos cada uma das etapas apresentando um passo a passo necessário.\n",
    "\n",
    "Quando for necessária execução externa ao notebook, indicaremos. No mais, utilizamos `boto3` para fazer tudo que for possível.\n",
    "\n",
    "Ps.: Esse notebook foi testado e executado no [ml.t3.xlarge](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-instance-types.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1c7837-f580-4779-82c5-f57da288191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ef791-9a3e-4f9d-81f8-78c620ed0122",
   "metadata": {},
   "source": [
    "## 1. Configurar os buckets no S3\n",
    "\n",
    "Ps.: Utilizar sempre a região Norte de Virgínia e o IAM Role deve ser LabRole\n",
    "\n",
    "1. Define um random number (vamos usar o account_id) para ser utilizado ao longo do notebook\n",
    "2. Criamos um bucket no S3 chamado `alv-cache-athena-{random_number}`\n",
    "3. Criamos um bucket no S3 chamado `alv-dl-{random_number}`\n",
    "    * Cria subpasta `imdb/landing-zone`\n",
    "    * Cria subpasta `imdb/brute-zone`\n",
    "        * Cria as subpastas:\n",
    "            * `name-basics`\n",
    "            * `title-akas`\n",
    "            * `title-basics`\n",
    "            * `title-crew`\n",
    "            * `title-episode`\n",
    "            * `title-principals`\n",
    "            * `title-ratings`\n",
    "    * Cria subpasta `imdb/out-zone`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccff274f-0d9d-4ea3-b49d-3351c111570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current AWS Region: us-east-1\n",
      "Current AWS Account ID: 667214058531\n"
     ]
    }
   ],
   "source": [
    "# Set default region\n",
    "region = \"us-east-1\"\n",
    "print(f\"Current AWS Region: {region}\")\n",
    "\n",
    "# Get account Id to be used as random number\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "print(f\"Current AWS Account ID: {account_id}\")\n",
    "\n",
    "# Define S3 client\n",
    "s3_client = boto3.client('s3', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54db809-bbb9-442a-b253-24ae6d149ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bucket names and creathe them\n",
    "def create_bucket(bucket_name: str, s3_client):\n",
    "    \"\"\"\n",
    "    Creates an S3 bucket if it does not already exist.\n",
    "    Handles region-specific creation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the region from the client\n",
    "        region = s3_client.meta.region_name\n",
    "\n",
    "        if region == 'us-east-1':\n",
    "            # 'us-east-1' is the default and doesn't need a LocationConstraint\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            # All other regions require a LocationConstraint\n",
    "            location_config = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(Bucket=bucket_name,\n",
    "                                    CreateBucketConfiguration=location_config)\n",
    "\n",
    "        print(f\"✅ Successfully created bucket: {bucket_name}\")\n",
    "\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        # Check for specific \"already exists\" errors\n",
    "        error_code = e.response['Error']['Code']\n",
    "        if error_code == 'BucketAlreadyOwnedByYou' or error_code == 'BucketAlreadyExists':\n",
    "            print(f\"⚠️ Bucket '{bucket_name}' already exists. Skipping creation.\")\n",
    "        else:\n",
    "            # Raise other errors (e.g., Access Denied)\n",
    "            print(f\"❌ Error creating bucket: {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8bb5b-69ef-4c5f-af8b-e4290f152dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(bucket_name: str, folder_name: str, s3_client):\n",
    "    \"\"\"\n",
    "    Creates an S3 \"folder\" (a zero-byte object with a trailing slash)\n",
    "    if it does not already exist.\n",
    "    \"\"\"\n",
    "    # Ensure folder name has a trailing slash\n",
    "    folder_key = folder_name.strip('/') + \"/\"\n",
    "\n",
    "    try:\n",
    "        # Check if the \"folder\" (object) already exists\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=folder_key)\n",
    "        print(f\"⚠️ Folder '{folder_name}' already exists in bucket '{bucket_name}'. Skipping creation.\")\n",
    "\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        # If a client error is thrown, check if it was a 404 error.\n",
    "        # If it was a 404 error, the \"folder\" does not exist.\n",
    "        error_code = e.response['Error']['Code']\n",
    "        if error_code == '404':\n",
    "            try:\n",
    "                # \"Folder\" not found, so create it by putting an empty object\n",
    "                s3_client.put_object(Bucket=bucket_name, Key=folder_key, Body='')\n",
    "                print(f\"✅ Successfully created '{folder_name}' in bucket '{bucket_name}'\")\n",
    "            except Exception as create_e:\n",
    "                print(f\"❌ Error creating folder: {create_e}\")\n",
    "                raise create_e\n",
    "        else:\n",
    "            # Some other error (e.g., 403 Forbidden)\n",
    "            print(f\"❌ Error checking folder: {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8946557-7b0c-4abf-80b7-0d490856a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name_cache_athena = f\"alv-cache-athena-{account_id}\"\n",
    "bucket_name_dl = f\"alv-dl-{account_id}\"\n",
    "folder_imdb = \"imdb\"\n",
    "folder_landing_zone = \"imdb/landing-zone\"\n",
    "folder_brute_zone = \"imdb/brute-zone\"\n",
    "folders_tables = [\n",
    "    \"name-basics\",\n",
    "    \"title-akas\",\n",
    "    \"title-basics\",\n",
    "    \"title-crew\",\n",
    "    \"title-episode\",\n",
    "    \"title-principals\",\n",
    "    \"title-ratings\",\n",
    "]\n",
    "folder_out_zone = \"imdb/out-zone\"\n",
    "\n",
    "# Create buckets\n",
    "create_bucket(bucket_name_cache_athena, s3_client)\n",
    "create_bucket(bucket_name_dl, s3_client)\n",
    "\n",
    "# Create folders\n",
    "create_folder(bucket_name_dl, folder_imdb, s3_client)\n",
    "create_folder(bucket_name_dl, folder_landing_zone, s3_client)\n",
    "create_folder(bucket_name_dl, folder_brute_zone, s3_client)\n",
    "\n",
    "for table in folders_tables:\n",
    "    create_folder(bucket_name_dl, f\"{folder_brute_zone}/{table}\", s3_client)\n",
    "\n",
    "create_folder(bucket_name_dl, folder_out_zone, s3_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd42cb-50a2-4144-acbb-afbe9b8bff25",
   "metadata": {},
   "source": [
    "## 2. Baixar os dados do IMDb\n",
    "\n",
    "1. Fazer o download do dump do IMDb\n",
    "2. Mover para a landing-zone no S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a182ec-0a4b-4e97-b83c-7f7b1cb9a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: name-basics\n",
      "\tDownloading...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  280M  100  280M    0     0   281M      0 --:--:-- --:--:-- --:--:--  281M\n",
      "\tUnzipping...\n",
      "\tMoving...\n",
      "Table: title-akas\n",
      "\tDownloading...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  446M  100  446M    0     0   256M      0  0:00:01  0:00:01 --:--:--  256M\n",
      "\tUnzipping...\n",
      "\tMoving...\n",
      "Table: title-basics\n",
      "\tDownloading...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  203M  100  203M    0     0   262M      0 --:--:-- --:--:-- --:--:--  262M\n",
      "\tUnzipping...\n",
      "\tMoving...\n",
      "Table: title-crew\n",
      "\tDownloading...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 75.0M  100 75.0M    0     0   224M      0 --:--:-- --:--:-- --:--:--  224M\n",
      "\tUnzipping...\n",
      "\tMoving...\n",
      "Table: title-episode\n",
      "\tDownloading...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 48.9M  100 48.9M    0     0   183M      0 --:--:-- --:--:-- --:--:--  184M\n",
      "\tUnzipping...\n",
      "\tMoving...\n",
      "Table: title-principals\n",
      "\tDownloading...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  704M  100  704M    0     0   432M      0  0:00:01  0:00:01 --:--:--  432M\n",
      "\tUnzipping...\n",
      "\tMoving...\n",
      "Table: title-ratings\n",
      "\tDownloading...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 8041k  100 8041k    0     0   214M      0 --:--:-- --:--:-- --:--:--  218M\n",
      "\tUnzipping...\n",
      "\tMoving...\n"
     ]
    }
   ],
   "source": [
    "imbd_zip_links = {\n",
    "    \"name-basics\": \"https://datasets.imdbws.com/name.basics.tsv.gz\",\n",
    "    \"title-akas\": \"https://datasets.imdbws.com/title.akas.tsv.gz\",\n",
    "    \"title-basics\": \"https://datasets.imdbws.com/title.basics.tsv.gz\",\n",
    "    \"title-crew\": \"https://datasets.imdbws.com/title.crew.tsv.gz\",\n",
    "    \"title-episode\": \"https://datasets.imdbws.com/title.episode.tsv.gz\",\n",
    "    \"title-principals\": \"https://datasets.imdbws.com/title.principals.tsv.gz\",\n",
    "    \"title-ratings\": \"https://datasets.imdbws.com/title.ratings.tsv.gz\",\n",
    "}\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "for table, url in imbd_zip_links.items():\n",
    "    zipped_file = f\"/tmp/{table}.tsv.gz\"\n",
    "    unzipped_file = f\"/tmp/{table}.tsv\"\n",
    "    print(f\"Table: {table}\")\n",
    "\n",
    "    print(\"\\tDownloading...\")\n",
    "    !curl {url} -o {zipped_file}\n",
    "\n",
    "    print(\"\\tUnzipping...\")\n",
    "    !gunzip -c {zipped_file} > {unzipped_file}\n",
    "\n",
    "    print(\"\\tMoving...\")\n",
    "    s3.meta.client.upload_file(unzipped_file, bucket_name_dl, f'{folder_landing_zone}/{table}.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76cbc6c-0a6c-4958-a6c2-41a53a50d175",
   "metadata": {},
   "source": [
    "## 3. Configurar o Glue para mapearmos os dados necessários\n",
    "\n",
    "1. Criar database no glue `imdb`\n",
    "2. Criar as tabelas no glue utilizando o esquema correto e o formato avro:\n",
    "    * `name-basics`\n",
    "    * `title-akas`\n",
    "    * `title-basics`\n",
    "    * `title-crew`\n",
    "    * `title-episode`\n",
    "    * `title-principals`\n",
    "    * `title-ratings`\n",
    "3. Criar um ETL com:\n",
    "    * Origem: arquivo da `landing-zone`\n",
    "    * Destino: tabela do glue\n",
    "    * Rodar job como: Update schema and add new partitions\n",
    "4. Criar crawler para ler tabela da `brute-zone`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7723bcf5-3e50-4284-93ea-3e14293fd9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema\n",
    "glue_schemas = {\n",
    "  \"title-akas\": [\n",
    "    {\"Name\": \"titleId\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"ordering\", \"Type\": \"bigint\"},\n",
    "    {\"Name\": \"title\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"region\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"language\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"types\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"attributes\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"isOriginalTitle\", \"Type\": \"bigint\"}\n",
    "  ],\n",
    "  \"title-basics\": [\n",
    "    {\"Name\": \"tconst\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"titleType\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"primaryTitle\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"originalTitle\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"isAdult\", \"Type\": \"bigint\"},\n",
    "    {\"Name\": \"startYear\", \"Type\": \"bigint\"},\n",
    "    {\"Name\": \"endYear\", \"Type\": \"bigint\"},\n",
    "    {\"Name\": \"runtimeMinutes\", \"Type\": \"bigint\"},\n",
    "    {\"Name\": \"genres\", \"Type\": \"string\"}\n",
    "  ],\n",
    "  \"title-crew\": [\n",
    "    {\"Name\": \"tconst\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"directors\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"writers\", \"Type\": \"string\"}\n",
    "  ],\n",
    "  \"title-episode\": [\n",
    "    {\"Name\": \"tconst\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"parentTconst\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"seasonNumber\", \"Type\": \"bigint\"},\n",
    "    {\"Name\": \"episodeNumber\", \"Type\": \"bigint\"}\n",
    "  ],\n",
    "  \"title-principals\": [\n",
    "    {\"Name\": \"tconst\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"ordering\", \"Type\": \"bigint\"},\n",
    "    {\"Name\": \"nconst\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"category\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"job\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"characters\", \"Type\": \"string\"}\n",
    "  ],\n",
    "  \"title-ratings\": [\n",
    "    {\"Name\": \"tconst\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"averageRating\", \"Type\": \"double\"},\n",
    "    {\"Name\": \"numVotes\", \"Type\": \"bigint\"}\n",
    "  ],\n",
    "  \"name-basics\": [\n",
    "    {\"Name\": \"nconst\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"primaryName\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"birthYear\", \"Type\": \"bigint\"},\n",
    "    {\"Name\": \"deathYear\", \"Type\": \"bigint\"},\n",
    "    {\"Name\": \"primaryProfession\", \"Type\": \"string\"},\n",
    "    {\"Name\": \"knownForTitles\", \"Type\": \"string\"}\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f11e19-e2a9-4335-8f9e-7ffa1c97eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database and tables\n",
    "def create_glue_database(database_name: str, glue_client):\n",
    "    try:\n",
    "        glue_client.create_database(\n",
    "            DatabaseInput={'Name': database_name}\n",
    "        )\n",
    "        print(f\"✅ Database '{database_name}' created successfully.\")\n",
    "    except glue_client.exceptions.AlreadyExistsException:\n",
    "        print(f\"❌ Database '{database_name}' already exists.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb0906-62d0-4520-9bb5-0db1b63e9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glue_table(\n",
    "    database_name: str,\n",
    "    table_name: str,\n",
    "    table_schema: list,\n",
    "    glue_client\n",
    "):\n",
    "    table_input = {\n",
    "        'Name': f'forma-vazia-{table_name}',\n",
    "        'Description': 'A table created manually from Boto3 for CSV data.',\n",
    "        'TableType': 'EXTERNAL_TABLE',\n",
    "        'Parameters': {\n",
    "            'classification': 'Avro',\n",
    "            'skip.header.line.count': '1',\n",
    "        },\n",
    "        'StorageDescriptor': {\n",
    "            'Columns': table_schema,\n",
    "            'Location': f's3://{bucket_name_dl}/{folder_brute_zone}/{table_name}',\n",
    "        },\n",
    "    }\n",
    "    try:\n",
    "        glue_client.create_table(\n",
    "            DatabaseName=database_name,\n",
    "            TableInput=table_input\n",
    "        )\n",
    "        print(f\"✅ Table '{table_name}' created successfully in database '{database_name}'.\")\n",
    "    except glue_client.exceptions.AlreadyExistsException:\n",
    "        print(f\"❌ Table '{table_name}' already exists.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating table: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57fe34d-0eca-4306-aee8-e371df35c0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Database 'imdb' already exists.\n",
      "❌ Table 'title-akas' already exists.\n",
      "❌ Table 'title-basics' already exists.\n",
      "❌ Table 'title-crew' already exists.\n",
      "❌ Table 'title-episode' already exists.\n",
      "❌ Table 'title-principals' already exists.\n",
      "❌ Table 'title-ratings' already exists.\n",
      "❌ Table 'name-basics' already exists.\n"
     ]
    }
   ],
   "source": [
    "glue_database_name = \"imdb\"\n",
    "glue_client = boto3.client('glue', region_name=region)\n",
    "\n",
    "create_glue_database(glue_database_name, glue_client)\n",
    "\n",
    "for table, schema in glue_schemas.items():\n",
    "    create_glue_table(glue_database_name, table, schema, glue_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2a7a5-4fee-4f64-84a1-e9b9bc2cb1c2",
   "metadata": {},
   "source": [
    "Ainda não conseguimos automatizar a parte de criação de ETL e de crawler, então precisa ser manual.\n",
    "\n",
    "Tabelas:\n",
    "* name-basics\n",
    "* title-akas\n",
    "* title-basic\n",
    "* title-crew\n",
    "* title-episode\n",
    "* title-principals\n",
    "* title-ratings\n",
    "\n",
    "Siga o passo a passo para cada uma das tabelas:\n",
    "\n",
    "1. Acesse o Glue\n",
    "2. Vá em visual ETL e crie um novo com\n",
    "    * Nome: `cria-forma-vazia-{table}`\n",
    "    * IAM Role: LabRole\n",
    "    * Origem: Amazon S3\n",
    "        * S3 URL: `s3://alv-dl-{account_id}/imdb/landing-zone/{table}.tsv`\n",
    "        * Data Format: CSV\n",
    "        * Delimiter: Tab\n",
    "    * Destino: AWS GLue Data Catalog\n",
    "        * Database: imdb\n",
    "        * Table: `forma-vazia-{table}`\n",
    "        * Update schema and add new partitions\n",
    "3. Execute o ETL\n",
    "4. Vá em Crawler e crie um novo com:\n",
    "    * Nome: `ler-{table}`\n",
    "    * Source: `s3://alv-dl-{account_id}/imdb/brute-zone/{table}/`\n",
    "    * IAM Role: LabRole\n",
    "    * Database: imdb\n",
    "5. Execute o Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb59cfb5-2475-430c-a5a7-60aaf0d646db",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYSPARK_ETL_SCRIPT = \"\"\"\n",
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "\n",
    "# Obter argumentos passados para o job\n",
    "args = getResolvedOptions(sys.argv, [\n",
    "    'JOB_NAME',\n",
    "    'S3_SOURCE_PATH',\n",
    "    'TARGET_DATABASE',\n",
    "    'TARGET_TABLE'\n",
    "])\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "\n",
    "print(f\"Iniciando job ETL para ler de: {args['S3_SOURCE_PATH']}\")\n",
    "\n",
    "# Origem: Ler o arquivo TSV (CSV com delimitador Tab) da landing-zone.\n",
    "# Assumimos que o arquivo tem cabeçalho (withHeader=True).\n",
    "dynamic_frame_source = glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type=\"s3\",\n",
    "    connection_options={\"paths\": [args['S3_SOURCE_PATH']]},\n",
    "    format=\"csv\",\n",
    "    format_options={\"separator\": \"\\\\t\", \"withHeader\": True}\n",
    ")\n",
    "\n",
    "print(f\"Gravando no destino: {args['TARGET_DATABASE']}.{args['TARGET_TABLE']}\")\n",
    "\n",
    "# Destino: Gravar no Glue Data Catalog.\n",
    "# A tabela de destino (forma-vazia-*) já foi definida com formato Avro.\n",
    "# O GlueContext cuidará da conversão de CSV (DynamicFrame) para Avro.\n",
    "# Isso implementa o \"Update schema and add new partitions\".\n",
    "glueContext.write_dynamic_frame.from_catalog(\n",
    "    frame=dynamic_frame_source,\n",
    "    database=args['TARGET_DATABASE'],\n",
    "    table_name=args['TARGET_TABLE']\n",
    ")\n",
    "\n",
    "job.commit()\n",
    "print(\"Job ETL concluído com sucesso.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8aad77c-0f6d-49c5-b936-45639ff85128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glue_etl(\n",
    "    glue_client,\n",
    "    s3_client,\n",
    "    table_name: str,\n",
    "    iam_role: str,\n",
    "    bucket_name_dl: str,\n",
    "    folder_scripts: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Automatiza a Etapa 2: Criação do Job ETL no Glue.\n",
    "\n",
    "    Isso envolve:\n",
    "    1. Fazer upload de um script PySpark gerado para o S3.\n",
    "    2. Criar um Glue Job que aponta para esse script.\n",
    "    \"\"\"\n",
    "    job_name = f\"cria-forma-vazia-{table_name}\"\n",
    "    script_key = f\"{folder_scripts.strip('/')}/{job_name}_script.py\"\n",
    "    script_s3_path = f\"s3://{bucket_name_dl}/{script_key}\"\n",
    "\n",
    "    try:\n",
    "        # 1. Fazer upload do script PySpark para o S3\n",
    "        print(f\"Fazendo upload do script ETL para: {script_s3_path}\")\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket_name_dl,\n",
    "            Key=script_key,\n",
    "            Body=PYSPARK_ETL_SCRIPT\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Erro ao fazer upload do script para S3: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # 2. Criar o Glue Job\n",
    "        print(f\"Criando Glue Job: {job_name}\")\n",
    "        glue_client.create_job(\n",
    "            Name=job_name,\n",
    "            Role=iam_role,\n",
    "            Command={\n",
    "                'Name': 'glueetl',\n",
    "                'ScriptLocation': script_s3_path,\n",
    "                'PythonVersion': '3'\n",
    "            },\n",
    "            GlueVersion='3.0',  # Usar 3.0 ou 4.0 é uma boa prática\n",
    "            Description=f'Job ETL para processar {table_name} do TSV para Avro',\n",
    "            DefaultArguments={\n",
    "                '--job-language': 'python'\n",
    "            }\n",
    "        )\n",
    "        print(f\"✅ Job '{job_name}' criado com sucesso.\")\n",
    "        return job_name\n",
    "\n",
    "    except glue_client.exceptions.AlreadyExistsException:\n",
    "        print(f\"⚠️ Job '{job_name}' já existe. Pulando criação.\")\n",
    "        return None\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Erro ao criar o Job: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c0ec29-3843-4cdc-8dcd-2beacc047407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_glue_etl(\n",
    "    glue_client,\n",
    "    table_name: str,\n",
    "    bucket_name_dl: str,\n",
    "    folder_landing_zone: str,\n",
    "    glue_database_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Automatiza a Etapa 3: Executa o Job ETL criado.\n",
    "    \"\"\"\n",
    "    job_name = f\"cria-forma-vazia-{table_name}\"\n",
    "    s3_source_path = f\"s3://{bucket_name_dl}/{folder_landing_zone.strip('/')}/{table_name}.tsv\"\n",
    "    target_table_name = f\"forma-vazia-{table_name}\"\n",
    "\n",
    "    try:\n",
    "        response = glue_client.start_job_run(\n",
    "            JobName=job_name,\n",
    "            Arguments={\n",
    "                '--S3_SOURCE_PATH': s3_source_path,\n",
    "                '--TARGET_DATABASE': glue_database_name,\n",
    "                '--TARGET_TABLE': target_table_name\n",
    "            }\n",
    "        )\n",
    "        job_run_id = response['JobRunId']\n",
    "        print(f\"✅ Job '{job_name}' iniciado com sucesso. Run ID: {job_run_id}\")\n",
    "        return job_run_id\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Erro ao iniciar o Job: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ddaf615-7676-43d1-b173-fe4412a2abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crawler(\n",
    "    glue_client,\n",
    "    table_name: str,\n",
    "    iam_role: str,\n",
    "    glue_database_name: str,\n",
    "    bucket_name_dl: str,\n",
    "    folder_brute_zone: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Automatiza a Etapa 4: Criação do Crawler do Glue.\n",
    "    \"\"\"\n",
    "    crawler_name = f\"ler-{table_name}\"\n",
    "    s3_target_path = f\"s3://{bucket_name_dl}/{folder_brute_zone.strip('/')}/{table_name}/\"\n",
    "\n",
    "    try:\n",
    "        glue_client.create_crawler(\n",
    "            Name=crawler_name,\n",
    "            Role=iam_role,\n",
    "            DatabaseName=glue_database_name,\n",
    "            Description=f'Crawler para ler dados da brute-zone de {table_name}',\n",
    "            Targets={\n",
    "                'S3Targets': [\n",
    "                    {\n",
    "                        'Path': s3_target_path\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            # Política para atualizar a tabela 'forma-vazia-{table}'\n",
    "            # que já aponta para este local S3.\n",
    "            SchemaChangePolicy={\n",
    "                'UpdateBehavior': 'UPDATE_IN_DATABASE',\n",
    "                'DeleteBehavior': 'LOG'  # Não deletar tabelas, apenas logar\n",
    "            }\n",
    "        )\n",
    "        print(f\"✅ Crawler '{crawler_name}' criado com sucesso.\")\n",
    "        return crawler_name\n",
    "\n",
    "    except glue_client.exceptions.AlreadyExistsException:\n",
    "        print(f\"⚠️ Crawler '{crawler_name}' já existe. Pulando criação.\")\n",
    "        return None\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Erro ao criar o Crawler: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a90c40f-7664-40a7-bc9e-0df6230eae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_crawler(glue_client, table_name: str):\n",
    "    \"\"\"\n",
    "    Automatiza a Etapa 5: Executa o Crawler.\n",
    "    \"\"\"\n",
    "    crawler_name = f\"ler-{table_name}\"\n",
    "\n",
    "    try:\n",
    "        # Verificar se o crawler não está rodando\n",
    "        crawler_state = glue_client.get_crawler(Name=crawler_name)['Crawler']['State']\n",
    "        if crawler_state == 'RUNNING':\n",
    "            print(f\"⚠️ Crawler '{crawler_name}' já está em execução.\")\n",
    "            return\n",
    "\n",
    "        glue_client.start_crawler(Name=crawler_name)\n",
    "        print(f\"✅ Crawler '{crawler_name}' iniciado com sucesso.\")\n",
    "\n",
    "    except glue_client.exceptions.CrawlerRunningException:\n",
    "        print(f\"⚠️ Crawler '{crawler_name}' já está em execução.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Erro ao iniciar o Crawler: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b817e756-eb3d-45ca-bb89-c80ef46965f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_crawler_to_finish(glue_client, crawler_name: str, delay_seconds: int = 10):\n",
    "    \"\"\"\n",
    "    Verifica manualmente o status de um Crawler até que ele termine.\n",
    "    O Boto3 não possui um waiter para 'crawler_completion'.\n",
    "    \"\"\"\n",
    "    print(f\"Aguardando o Crawler '{crawler_name}' terminar...\")\n",
    "    while True:\n",
    "        try:\n",
    "            response = glue_client.get_crawler(Name=crawler_name)\n",
    "            state = response['Crawler']['State']\n",
    "\n",
    "            if state == 'READY':\n",
    "                # O crawler terminou e está pronto para a próxima execução\n",
    "                print(f\"\\t✅ Crawler concluiu com sucesso.\")\n",
    "                break\n",
    "            elif state == 'RUNNING' or state == 'STOPPING':\n",
    "                # Ainda está em execução, continue esperando\n",
    "                print(f\"\\tCrawler ainda está no estado: {state}...\")\n",
    "                time.sleep(delay_seconds)\n",
    "            else:\n",
    "                # O crawler falhou ou foi interrompido\n",
    "                last_crawl = response['Crawler'].get('LastCrawl', {})\n",
    "                error_message = last_crawl.get('ErrorMessage', 'Estado de falha desconhecido.')\n",
    "                print(f\"\\t❌ Crawler falhou ou parou. \\n\\t\\tEstado: {state}. \\n\\t\\tErro: {error_message}\")\n",
    "                raise Exception(f\"Crawler {crawler_name} falhou: {error_message}\")\n",
    "\n",
    "        except ClientError as e:\n",
    "            print(f\"❌ Erro ao verificar o status do crawler: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e90ee116-478a-44d3-9061-e07038d2a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_etl_run_to_finish(\n",
    "    glue_client,\n",
    "    job_name: str,\n",
    "    run_id: str,\n",
    "    delay_seconds: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    Verifica manualmente o status de um Glue Job Run até que ele termine.\n",
    "    \"\"\"\n",
    "    print(f\"Aguardando o Job Run '{job_name}' (Run ID: {run_id}) terminar...\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = glue_client.get_job_run(JobName=job_name, RunId=run_id)\n",
    "            state = response['JobRun']['JobRunState']\n",
    "\n",
    "            if state == 'SUCCEEDED':\n",
    "                # O job terminou com sucesso\n",
    "                print(\"\\t✅ Job Run concluiu com sucesso.\")\n",
    "                break\n",
    "\n",
    "            elif state in ('RUNNING', 'STARTING', 'STOPPING', 'WAITING'):\n",
    "                # Ainda está em execução, continue esperando\n",
    "                print(f\"\\tJob Run ainda está no estado: {state}....\")\n",
    "                time.sleep(delay_seconds)\n",
    "\n",
    "            elif state in ('FAILED', 'STOPPED', 'TIMEOUT'):\n",
    "                # O job falhou, foi parado ou deu timeout\n",
    "                error_message = response['JobRun'].get('ErrorMessage', 'Estado de falha desconhecido.')\n",
    "                print(f\"\\t❌ Job Run '{job_name}' (Run ID: {run_id}) falhou ou parou. \\n\\t\\tEstado: {state}. \\n\\t\\tErro: {error_message}\")\n",
    "                raise Exception(f\"Job Run {job_name} (Run ID: {run_id}) falhou: {error_message}\")\n",
    "\n",
    "            else:\n",
    "                # Um estado inesperado\n",
    "                print(f\"\\t❌ Job Run '{job_name}' (Run ID: {run_id}) está em estado desconhecido: {state}\")\n",
    "                raise Exception(f\"Estado desconhecido para Job Run {job_name} (Run ID: {run_id}): {state}\")\n",
    "\n",
    "        except ClientError as e:\n",
    "            # Lidar com erros de API, como \"ThrottlingException\"\n",
    "            error_code = e.response.get('Error', {}).get('Code')\n",
    "            if error_code == 'ThrottlingException':\n",
    "                print(f\"Throttling detectado. Aguardando {delay_seconds}s antes de tentar novamente...\")\n",
    "                time.sleep(delay_seconds)\n",
    "            else:\n",
    "                print(f\"❌ Erro ao verificar o status do Job Run: {e}\")\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd93373e-72df-4055-9b89-552bc25ede9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IAM_ROLE = \"LabRole\"\n",
    "GLUE_DATABASE_NAME = \"imdb\"\n",
    "FOLDER_SCRIPTS = \"imdb/scripts\"\n",
    "\n",
    "tables_to_process = [\n",
    "    \"name-basics\",\n",
    "    \"title-akas\",\n",
    "    \"title-basics\",\n",
    "    \"title-crew\",\n",
    "    \"title-episode\",\n",
    "    \"title-principals\",\n",
    "    \"title-ratings\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad36a6d2-0708-4f49-8602-f96fa3ca5582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fazendo upload do script ETL para: s3://alv-dl-667214058531/imdb/scripts/cria-forma-vazia-title-basics_script.py\n",
      "Criando Glue Job: cria-forma-vazia-title-basics\n",
      "✅ Job 'cria-forma-vazia-title-basics' criado com sucesso.\n",
      "✅ Job 'cria-forma-vazia-title-basics' iniciado com sucesso. Run ID: jr_0d76db0e505a4b5c9c34f095be1173601848526edb80f48c7ad4555db7661df1\n",
      "Fazendo upload do script ETL para: s3://alv-dl-667214058531/imdb/scripts/cria-forma-vazia-title-crew_script.py\n",
      "Criando Glue Job: cria-forma-vazia-title-crew\n",
      "✅ Job 'cria-forma-vazia-title-crew' criado com sucesso.\n",
      "✅ Job 'cria-forma-vazia-title-crew' iniciado com sucesso. Run ID: jr_0e632e4b9d6dd31fd544745112e754f58bc464b698ea964d87c8d65d3e05bc30\n",
      "Fazendo upload do script ETL para: s3://alv-dl-667214058531/imdb/scripts/cria-forma-vazia-title-episode_script.py\n",
      "Criando Glue Job: cria-forma-vazia-title-episode\n",
      "✅ Job 'cria-forma-vazia-title-episode' criado com sucesso.\n",
      "✅ Job 'cria-forma-vazia-title-episode' iniciado com sucesso. Run ID: jr_f121cf39b59d4ac8a9b6e6a39639b89e9533d00192bb886f0c05a69ee42528f5\n",
      "Fazendo upload do script ETL para: s3://alv-dl-667214058531/imdb/scripts/cria-forma-vazia-title-principals_script.py\n",
      "Criando Glue Job: cria-forma-vazia-title-principals\n",
      "✅ Job 'cria-forma-vazia-title-principals' criado com sucesso.\n",
      "✅ Job 'cria-forma-vazia-title-principals' iniciado com sucesso. Run ID: jr_db9f0789c3c0044c9e286e13b1739de591e0f176918366d71ca502826ff635fa\n",
      "Fazendo upload do script ETL para: s3://alv-dl-667214058531/imdb/scripts/cria-forma-vazia-title-ratings_script.py\n",
      "Criando Glue Job: cria-forma-vazia-title-ratings\n",
      "✅ Job 'cria-forma-vazia-title-ratings' criado com sucesso.\n",
      "✅ Job 'cria-forma-vazia-title-ratings' iniciado com sucesso. Run ID: jr_615e416c80e2620e37dbdcb4786504e1d03b71f12ba37805ec5b593026427dc7\n"
     ]
    }
   ],
   "source": [
    "# Create ETLs\n",
    "job_runs_names_and_ids = []\n",
    "for table in tables_to_process:\n",
    "    job_name = create_glue_etl(\n",
    "        glue_client,\n",
    "        s3_client,\n",
    "        table,\n",
    "        IAM_ROLE,\n",
    "        bucket_name_dl,\n",
    "        FOLDER_SCRIPTS\n",
    "    )\n",
    "\n",
    "    if job_name is None:\n",
    "        continue\n",
    "\n",
    "    job_run_id = run_glue_etl(\n",
    "        glue_client,\n",
    "        table,\n",
    "        bucket_name_dl,\n",
    "        folder_landing_zone,\n",
    "        GLUE_DATABASE_NAME\n",
    "    )\n",
    "    job_runs_names_and_ids.append((job_name, job_run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68bd51df-0e8e-441b-aed8-a47643d8b59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aguardando o Job Run 'cria-forma-vazia-title-basics' (Run ID: jr_0d76db0e505a4b5c9c34f095be1173601848526edb80f48c7ad4555db7661df1) terminar...\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\t✅ Job Run concluiu com sucesso.\n",
      "Aguardando o Job Run 'cria-forma-vazia-title-crew' (Run ID: jr_0e632e4b9d6dd31fd544745112e754f58bc464b698ea964d87c8d65d3e05bc30) terminar...\n",
      "\t✅ Job Run concluiu com sucesso.\n",
      "Aguardando o Job Run 'cria-forma-vazia-title-episode' (Run ID: jr_f121cf39b59d4ac8a9b6e6a39639b89e9533d00192bb886f0c05a69ee42528f5) terminar...\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\t✅ Job Run concluiu com sucesso.\n",
      "Aguardando o Job Run 'cria-forma-vazia-title-principals' (Run ID: jr_db9f0789c3c0044c9e286e13b1739de591e0f176918366d71ca502826ff635fa) terminar...\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\tJob Run ainda está no estado: RUNNING....\n",
      "\t✅ Job Run concluiu com sucesso.\n",
      "Aguardando o Job Run 'cria-forma-vazia-title-ratings' (Run ID: jr_615e416c80e2620e37dbdcb4786504e1d03b71f12ba37805ec5b593026427dc7) terminar...\n",
      "\t✅ Job Run concluiu com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Wait until all etls ends\n",
    "for job_name, job_run_id in job_runs_names_and_ids:\n",
    "    wait_for_etl_run_to_finish(glue_client, job_name, job_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f6a7bf2-d5e7-46e5-909d-084d3e542d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Crawler 'ler-title-basics' criado com sucesso.\n",
      "✅ Crawler 'ler-title-basics' iniciado com sucesso.\n",
      "✅ Crawler 'ler-title-crew' criado com sucesso.\n",
      "✅ Crawler 'ler-title-crew' iniciado com sucesso.\n",
      "✅ Crawler 'ler-title-episode' criado com sucesso.\n",
      "✅ Crawler 'ler-title-episode' iniciado com sucesso.\n",
      "✅ Crawler 'ler-title-principals' criado com sucesso.\n",
      "✅ Crawler 'ler-title-principals' iniciado com sucesso.\n",
      "✅ Crawler 'ler-title-ratings' criado com sucesso.\n",
      "✅ Crawler 'ler-title-ratings' iniciado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Crawlers\n",
    "crawlers_names = []\n",
    "for table in tables_to_process:\n",
    "    # Create crawler\n",
    "    crawler_name = create_crawler(\n",
    "        glue_client,\n",
    "        table,\n",
    "        IAM_ROLE,\n",
    "        GLUE_DATABASE_NAME,\n",
    "        bucket_name_dl,\n",
    "        folder_brute_zone\n",
    "    )\n",
    "\n",
    "    if crawler_name is None:\n",
    "        continue\n",
    "\n",
    "    # Run crawler\n",
    "    run_crawler(glue_client, table)\n",
    "\n",
    "    crawlers_names.append(crawler_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "615478d2-321a-4916-af1e-2bd5ef8842a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aguardando o Crawler 'ler-title-basics' terminar...\n",
      "\tCrawler ainda está no estado: RUNNING...\n",
      "\tCrawler ainda está no estado: RUNNING...\n",
      "\tCrawler ainda está no estado: RUNNING...\n",
      "\t✅ Crawler concluiu com sucesso.\n",
      "Aguardando o Crawler 'ler-title-crew' terminar...\n",
      "\t✅ Crawler concluiu com sucesso.\n",
      "Aguardando o Crawler 'ler-title-episode' terminar...\n",
      "\tCrawler ainda está no estado: RUNNING...\n",
      "\tCrawler ainda está no estado: STOPPING...\n",
      "\tCrawler ainda está no estado: STOPPING...\n",
      "\tCrawler ainda está no estado: STOPPING...\n",
      "\tCrawler ainda está no estado: STOPPING...\n",
      "\tCrawler ainda está no estado: STOPPING...\n",
      "\tCrawler ainda está no estado: STOPPING...\n",
      "\tCrawler ainda está no estado: STOPPING...\n",
      "\t✅ Crawler concluiu com sucesso.\n",
      "Aguardando o Crawler 'ler-title-principals' terminar...\n",
      "\t✅ Crawler concluiu com sucesso.\n",
      "Aguardando o Crawler 'ler-title-ratings' terminar...\n",
      "\tCrawler ainda está no estado: STOPPING...\n",
      "\tCrawler ainda está no estado: STOPPING...\n",
      "\tCrawler ainda está no estado: STOPPING...\n",
      "\t✅ Crawler concluiu com sucesso.\n"
     ]
    }
   ],
   "source": [
    "for crawler_name in crawlers_names:\n",
    "    wait_for_crawler_to_finish(glue_client, crawler_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe4dc0d-ff5b-4002-a439-fd28b45c5a18",
   "metadata": {},
   "source": [
    "## 4. Breve visualização dos dados utilizando pyathena\n",
    "\n",
    "1. Entender volume dos dados\n",
    "2. Entender quais tabelas precisam ser cruzadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4972dcc4-2e41-40a4-b0a5-ee1ede7c787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyathena[sqlalchemy]\n",
      "  Downloading pyathena-3.21.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: boto3>=1.26.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pyathena[sqlalchemy]) (1.40.69)\n",
      "Requirement already satisfied: botocore>=1.29.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pyathena[sqlalchemy]) (1.40.69)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pyathena[sqlalchemy]) (2025.10.0)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pyathena[sqlalchemy]) (2.9.0)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pyathena[sqlalchemy]) (9.1.2)\n",
      "Collecting sqlalchemy>=1.0.0 (from pyathena[sqlalchemy])\n",
      "  Downloading sqlalchemy-2.0.44-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.26.4->pyathena[sqlalchemy]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.26.4->pyathena[sqlalchemy]) (0.14.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore>=1.29.4->pyathena[sqlalchemy]) (1.26.20)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil->pyathena[sqlalchemy]) (1.17.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.0.0->pyathena[sqlalchemy])\n",
      "  Downloading greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sqlalchemy>=1.0.0->pyathena[sqlalchemy]) (4.15.0)\n",
      "Downloading pyathena-3.21.0-py3-none-any.whl (112 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (584 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.4/584.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: greenlet, sqlalchemy, pyathena\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pyathena]2/3\u001b[0m [pyathena]y]\n",
      "\u001b[1A\u001b[2KSuccessfully installed greenlet-3.2.4 pyathena-3.21.0 sqlalchemy-2.0.44\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install \"pyathena[sqlalchemy]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c42d361-6eae-4175-9090-abc57585a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import unicodedata\n",
    "import re\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c9901a4-ba3c-4f53-99a5-cef89f35f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_staging_dir = f\"s3://{bucket_name_cache_athena}/\"\n",
    "\n",
    "def get_table_name(table):\n",
    "    return f'\"{glue_name_database}\".\"{table}\"'\n",
    "\n",
    "engine = create_engine(f\"awsathena+rest://@athena.{region}.amazonaws.com:443/{glue_name_database}?s3_staging_dir={s3_staging_dir}\")  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bdec1441-1703-4b84-886d-c3bfa8828f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: name_basics\n",
      "\tTamanho: 14,863,018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nconst</th>\n",
       "      <th>primaryname</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>deathyear</th>\n",
       "      <th>primaryprofession</th>\n",
       "      <th>knownfortitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm0000001</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899</td>\n",
       "      <td>1987</td>\n",
       "      <td>actor,miscellaneous,producer</td>\n",
       "      <td>tt0072308,tt0050419,tt0027125,tt0025164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0000002</td>\n",
       "      <td>Lauren Bacall</td>\n",
       "      <td>1924</td>\n",
       "      <td>2014</td>\n",
       "      <td>actress,miscellaneous,soundtrack</td>\n",
       "      <td>tt0037382,tt0075213,tt0038355,tt0117057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0000003</td>\n",
       "      <td>Brigitte Bardot</td>\n",
       "      <td>1934</td>\n",
       "      <td>\\N</td>\n",
       "      <td>actress,music_department,producer</td>\n",
       "      <td>tt0057345,tt0049189,tt0056404,tt0054452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0000004</td>\n",
       "      <td>John Belushi</td>\n",
       "      <td>1949</td>\n",
       "      <td>1982</td>\n",
       "      <td>actor,writer,music_department</td>\n",
       "      <td>tt0072562,tt0077975,tt0080455,tt0078723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0000005</td>\n",
       "      <td>Ingmar Bergman</td>\n",
       "      <td>1918</td>\n",
       "      <td>2007</td>\n",
       "      <td>writer,director,actor</td>\n",
       "      <td>tt0050986,tt0069467,tt0083922,tt0050976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nconst      primaryname birthyear deathyear  \\\n",
       "0  nm0000001     Fred Astaire      1899      1987   \n",
       "1  nm0000002    Lauren Bacall      1924      2014   \n",
       "2  nm0000003  Brigitte Bardot      1934        \\N   \n",
       "3  nm0000004     John Belushi      1949      1982   \n",
       "4  nm0000005   Ingmar Bergman      1918      2007   \n",
       "\n",
       "                   primaryprofession                           knownfortitles  \n",
       "0       actor,miscellaneous,producer  tt0072308,tt0050419,tt0027125,tt0025164  \n",
       "1   actress,miscellaneous,soundtrack  tt0037382,tt0075213,tt0038355,tt0117057  \n",
       "2  actress,music_department,producer  tt0057345,tt0049189,tt0056404,tt0054452  \n",
       "3      actor,writer,music_department  tt0072562,tt0077975,tt0080455,tt0078723  \n",
       "4              writer,director,actor  tt0050986,tt0069467,tt0083922,tt0050976  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: title_akas\n",
      "\tTamanho: 53,779,343\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titleid</th>\n",
       "      <th>ordering</th>\n",
       "      <th>title</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "      <th>types</th>\n",
       "      <th>attributes</th>\n",
       "      <th>isoriginaltitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0145015</td>\n",
       "      <td>1</td>\n",
       "      <td>Júlia Pastrana</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>original</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0145015</td>\n",
       "      <td>2</td>\n",
       "      <td>Júlia Pastrana</td>\n",
       "      <td>BR</td>\n",
       "      <td>\\N</td>\n",
       "      <td>imdbDisplay</td>\n",
       "      <td>\\N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0145016</td>\n",
       "      <td>1</td>\n",
       "      <td>O kabouris</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>original</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0145016</td>\n",
       "      <td>2</td>\n",
       "      <td>The Hunchback</td>\n",
       "      <td>GB</td>\n",
       "      <td>\\N</td>\n",
       "      <td>imdbDisplay</td>\n",
       "      <td>\\N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0145016</td>\n",
       "      <td>3</td>\n",
       "      <td>The Hunchback</td>\n",
       "      <td>US</td>\n",
       "      <td>\\N</td>\n",
       "      <td>imdbDisplay</td>\n",
       "      <td>\\N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     titleid ordering           title region language        types attributes  \\\n",
       "0  tt0145015        1  Júlia Pastrana     \\N       \\N     original         \\N   \n",
       "1  tt0145015        2  Júlia Pastrana     BR       \\N  imdbDisplay         \\N   \n",
       "2  tt0145016        1      O kabouris     \\N       \\N     original         \\N   \n",
       "3  tt0145016        2   The Hunchback     GB       \\N  imdbDisplay         \\N   \n",
       "4  tt0145016        3   The Hunchback     US       \\N  imdbDisplay         \\N   \n",
       "\n",
       "  isoriginaltitle  \n",
       "0               1  \n",
       "1               0  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: title_basics\n",
      "\tTamanho: 24,095,050\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titletype</th>\n",
       "      <th>primarytitle</th>\n",
       "      <th>originaltitle</th>\n",
       "      <th>isadult</th>\n",
       "      <th>startyear</th>\n",
       "      <th>endyear</th>\n",
       "      <th>runtimeminutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt11125930</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Chance the Rapper</td>\n",
       "      <td>Chance the Rapper</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>\\N</td>\n",
       "      <td>90</td>\n",
       "      <td>Comedy,Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt11125932</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Kristen Stewart/Coldplay</td>\n",
       "      <td>Kristen Stewart/Coldplay</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>\\N</td>\n",
       "      <td>90</td>\n",
       "      <td>Comedy,Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt11125936</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Jay-Z</td>\n",
       "      <td>Jay-Z</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Biography,Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt11125938</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>EP402 - Whilma's Filipino Restaurant</td>\n",
       "      <td>EP402 - Whilma's Filipino Restaurant</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt1112594</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Episode #3.11</td>\n",
       "      <td>Episode #3.11</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tconst  titletype                          primarytitle  \\\n",
       "0  tt11125930  tvEpisode                     Chance the Rapper   \n",
       "1  tt11125932  tvEpisode              Kristen Stewart/Coldplay   \n",
       "2  tt11125936  tvEpisode                                 Jay-Z   \n",
       "3  tt11125938  tvEpisode  EP402 - Whilma's Filipino Restaurant   \n",
       "4   tt1112594  tvEpisode                         Episode #3.11   \n",
       "\n",
       "                          originaltitle isadult startyear endyear  \\\n",
       "0                     Chance the Rapper       0      2019      \\N   \n",
       "1              Kristen Stewart/Coldplay       0      2019      \\N   \n",
       "2                                 Jay-Z       0      2000      \\N   \n",
       "3  EP402 - Whilma's Filipino Restaurant       0      2019      \\N   \n",
       "4                         Episode #3.11       0      2007      \\N   \n",
       "\n",
       "  runtimeminutes                 genres  \n",
       "0             90           Comedy,Music  \n",
       "1             90           Comedy,Music  \n",
       "2             \\N  Biography,Documentary  \n",
       "3             \\N            Documentary  \n",
       "4             \\N                     \\N  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: title_crew\n",
      "\tTamanho: 12,052,394\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>directors</th>\n",
       "      <th>writers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt38069463</td>\n",
       "      <td>nm11479487</td>\n",
       "      <td>nm11498549,nm14915707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt38069464</td>\n",
       "      <td>nm11479487</td>\n",
       "      <td>nm11498549,nm14915707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt38069465</td>\n",
       "      <td>nm11479487</td>\n",
       "      <td>nm11498549,nm14915707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt38069466</td>\n",
       "      <td>nm11479487</td>\n",
       "      <td>nm11498549,nm14915707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt38069467</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tconst   directors                writers\n",
       "0  tt38069463  nm11479487  nm11498549,nm14915707\n",
       "1  tt38069464  nm11479487  nm11498549,nm14915707\n",
       "2  tt38069465  nm11479487  nm11498549,nm14915707\n",
       "3  tt38069466  nm11479487  nm11498549,nm14915707\n",
       "4  tt38069467          \\N                     \\N"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: title_episode\n",
      "\tTamanho: 9,288,054\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>parenttconst</th>\n",
       "      <th>seasonnumber</th>\n",
       "      <th>episodenumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt33253302</td>\n",
       "      <td>tt13777138</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt33253304</td>\n",
       "      <td>tt0795129</td>\n",
       "      <td>196</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt33253305</td>\n",
       "      <td>tt27119289</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt33253306</td>\n",
       "      <td>tt0184090</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt33253307</td>\n",
       "      <td>tt13198896</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tconst parenttconst seasonnumber episodenumber\n",
       "0  tt33253302   tt13777138            4           123\n",
       "1  tt33253304    tt0795129          196             9\n",
       "2  tt33253305   tt27119289           \\N            \\N\n",
       "3  tt33253306    tt0184090           \\N            \\N\n",
       "4  tt33253307   tt13198896           \\N            \\N"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: title_principals\n",
      "\tTamanho: 95,751,042\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>ordering</th>\n",
       "      <th>nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt10099562</td>\n",
       "      <td>12</td>\n",
       "      <td>nm0438471</td>\n",
       "      <td>writer</td>\n",
       "      <td>developed by</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt10099562</td>\n",
       "      <td>13</td>\n",
       "      <td>nm3813965</td>\n",
       "      <td>writer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt10099562</td>\n",
       "      <td>14</td>\n",
       "      <td>nm1941818</td>\n",
       "      <td>writer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt10099562</td>\n",
       "      <td>15</td>\n",
       "      <td>nm8827833</td>\n",
       "      <td>writer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt10099562</td>\n",
       "      <td>16</td>\n",
       "      <td>nm0438506</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tconst ordering     nconst  category           job characters\n",
       "0  tt10099562       12  nm0438471    writer  developed by         \\N\n",
       "1  tt10099562       13  nm3813965    writer            \\N         \\N\n",
       "2  tt10099562       14  nm1941818    writer            \\N         \\N\n",
       "3  tt10099562       15  nm8827833    writer            \\N         \\N\n",
       "4  tt10099562       16  nm0438506  producer      producer         \\N"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: title_ratings\n",
      "\tTamanho: 1,635,210\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>averagerating</th>\n",
       "      <th>numvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>5.5</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>5.2</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst averagerating numvotes\n",
       "0  tt0000001           5.7     2184\n",
       "1  tt0000002           5.5      305\n",
       "2  tt0000003           6.4     2264\n",
       "3  tt0000004           5.2      196\n",
       "4  tt0000005           6.2     3007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tables = [\n",
    "    \"name_basics\",\n",
    "    \"title_akas\",\n",
    "    \"title_basics\",\n",
    "    \"title_crew\",\n",
    "    \"title_episode\",\n",
    "    \"title_principals\",\n",
    "    \"title_ratings\",\n",
    "]\n",
    "\n",
    "for table in tables:\n",
    "    df_table = pd.read_sql(f\"SELECT * FROM {get_table_name(table)} LIMIT 5;\", engine)\n",
    "    size = pd.read_sql(f\"SELECT COUNT(*) FROM {get_table_name(table)};\", engine).iloc[0].iloc[0]\n",
    "    print(f\"Table: {table}\")\n",
    "    print(f\"\\tTamanho: {float(size):,.0f}\")\n",
    "    display(df_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959dcb4-7ec1-4027-8862-ede50d1a1398",
   "metadata": {},
   "source": [
    "## 5. Utilizar o pyathena para executar as queries necessárias e gerar o output final\n",
    "\n",
    "1. Fazer query necessária\n",
    "2. Definir critério de ordenação\n",
    "3. Salvar output em um csv na `out-zone`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4162317b-39d4-4250-ad6e-937af815adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pd.read_sql(\n",
    "    f\"\"\"\n",
    "        SELECT *\n",
    "        FROM {get_table_name('title_basics')} AS tb\n",
    "        INNER JOIN {get_table_name('title_ratings')} AS tr\n",
    "            ON tb.tconst = tr.tconst\n",
    "        WHERE tb.titletype = 'movie';\n",
    "    \"\"\",\n",
    "    engine,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d685089-17fe-47a4-b938-457217b6a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'tconst': str,\n",
    "    'titletype': str,\n",
    "    'primarytitle': str,\n",
    "    'originaltitle': str,\n",
    "    'isadult': float,\n",
    "    'startyear': float,\n",
    "    'endyear': float,\n",
    "    'runtimeminutes': float,\n",
    "    'genres': int,\n",
    "    'averagerating': float,\n",
    "    'numvotes': float,\n",
    "}\n",
    "\n",
    "for col, dtype in dtypes.items():\n",
    "    if dtype is float:\n",
    "        movie_data[col] = pd.to_numeric(movie_data[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba3fa941-470e-475e-b70d-f8715955a15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averagerating</th>\n",
       "      <th>numvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>676916.000000</td>\n",
       "      <td>6.769160e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.137554</td>\n",
       "      <td>3.646642e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.380100</td>\n",
       "      <td>3.719413e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.300000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.200000</td>\n",
       "      <td>6.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>3.180000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.117805e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       averagerating      numvotes\n",
       "count  676916.000000  6.769160e+05\n",
       "mean        6.137554  3.646642e+03\n",
       "std         1.380100  3.719413e+04\n",
       "min         1.000000  5.000000e+00\n",
       "25%         5.300000  2.000000e+01\n",
       "50%         6.200000  6.200000e+01\n",
       "75%         7.100000  3.180000e+02\n",
       "max        10.000000  3.117805e+06"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data[['averagerating', 'numvotes']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f075aad5-08dd-4518-be21-1c1376fcf2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>primarytitle</th>\n",
       "      <th>startyear</th>\n",
       "      <th>runtimeminutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>averagerating</th>\n",
       "      <th>numvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt37561269</td>\n",
       "      <td>Raju Gaani Savaal</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt12119248</td>\n",
       "      <td>Manmauji</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>9.6</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt34000241</td>\n",
       "      <td>Mannu Kya Karegga</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>9.5</td>\n",
       "      <td>3103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt36460794</td>\n",
       "      <td>Kousalya Tanaya Ragava</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt33505969</td>\n",
       "      <td>Irudhi Muyarchi</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37371</th>\n",
       "      <td>tt0023878</td>\n",
       "      <td>Central Airport</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>6.2</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37372</th>\n",
       "      <td>tt0076754</td>\n",
       "      <td>The Swindle</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>6.2</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37373</th>\n",
       "      <td>tt6504868</td>\n",
       "      <td>Sadie</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>6.2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37374</th>\n",
       "      <td>tt4256516</td>\n",
       "      <td>America, Here We Come</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>6.2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37375</th>\n",
       "      <td>tt5073756</td>\n",
       "      <td>All at Once</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>6.2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37376 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tconst            primarytitle  startyear  runtimeminutes  genres  \\\n",
       "0      tt37561269       Raju Gaani Savaal     2025.0           113.0  Action   \n",
       "1      tt12119248                Manmauji     2024.0           138.0   Drama   \n",
       "2      tt34000241       Mannu Kya Karegga     2025.0           141.0   Drama   \n",
       "3      tt36460794  Kousalya Tanaya Ragava     2025.0           147.0      \\N   \n",
       "4      tt33505969         Irudhi Muyarchi     2025.0           121.0      \\N   \n",
       "...           ...                     ...        ...             ...     ...   \n",
       "37371   tt0023878         Central Airport     1933.0            72.0   Drama   \n",
       "37372   tt0076754             The Swindle     1977.0            99.0  Action   \n",
       "37373   tt6504868                   Sadie     2018.0            96.0   Drama   \n",
       "37374   tt4256516   America, Here We Come     2014.0            90.0  Comedy   \n",
       "37375   tt5073756             All at Once     2016.0           112.0   Drama   \n",
       "\n",
       "       averagerating  numvotes  \n",
       "0                9.6      1078  \n",
       "1                9.6       757  \n",
       "2                9.5      3103  \n",
       "3                9.5      1212  \n",
       "4                9.5      1042  \n",
       "...              ...       ...  \n",
       "37371            6.2       501  \n",
       "37372            6.2       501  \n",
       "37373            6.2       500  \n",
       "37374            6.2       500  \n",
       "37375            6.2       500  \n",
       "\n",
       "[37376 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = movie_data[\n",
    "    (movie_data[\"averagerating\"] >= 6.2)\n",
    "    & (movie_data[\"numvotes\"] >= 500)\n",
    "][[\"tconst\", \"primarytitle\", \"startyear\", \"runtimeminutes\", \"genres\", \"averagerating\", \"numvotes\"]]\n",
    "\n",
    "df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "\n",
    "df = df.drop_duplicates('tconst')\n",
    "\n",
    "# slice genres to get only first\n",
    "df['genres'] = df['genres'].str.split(',', expand=True)[0]\n",
    "\n",
    "df = df.sort_values(['averagerating', 'numvotes'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c3c545f7-f8e4-45cd-b3e3-9268c8380452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download link: https://alv-dl-667214058531.s3.amazonaws.com/imdb/out-zone/output.parquet?AWSAccessKeyId=ASIAZWWIOSQRZZPMFRCO&Signature=UywApicjdPGkACJAEHtkDceqDN8%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEGIaCXVzLWVhc3QtMSJGMEQCIDNj4ospzfTVkAfKNENi8kgKHPMLF2GVN4aDljTcf6dfAiBDttRwxqWSs6jD%2BFQZDCKhJvoaZTHsOsNJdT42JQUT%2BCq2AggrEAAaDDY2NzIxNDA1ODUzMSIM6I3F0r7wCij30LM4KpMCe6Fd%2FxqT99HFtJZswIAO5AGuy83jL%2F9Vyp6zsq8PXJQg2BUMoIJF52W6mvPqIucF5mUfdNw1sUC%2B74Nh2iKm%2BiLT7uNaiJYeMg2k6XhyzLuj4ptUPMkH%2F13wCbAIvNVo1RrQUhxkMy9%2BJbaHe8yNnWGpaSQOapcmHMtAVlCVcbn265WHXNHP6ZX0op3R1SK46fh8diB%2FDlJFcOXwZhOvZiphvYRjID23JdXpbMEST613IThiCFVnnCjpAogTeMv1fXqbHMuiyM4MSghnOEe0FEVsJt%2Fa2m7FtotRWWfqhk5jJcabp%2FcD%2B3UyMLSFY80OsCuyWUAnIY48uQQ1bJ4ga%2Fn44pw00DKSeSmA2GyZR6M4cyMwvMTPyAY6kgGYgJiSV2iMzRSN%2Bkvu1reoM5QYnxOnQ%2Fne2vBMuGOoBVdgbez8gKz0Hi7LvvA3t4nG2txd1sb2ypa3HQXsvtTOpN5xtbI5mzrT5log5VQzGf%2Bioi5Bszo7o8zZw6Q9a1KABE%2BthP5vZ8LYPO964dcw%2FGuaxgt6CCYWqkplgVeq5xffuonn4hVPovJfwQPe%2FayC5w%3D%3D&Expires=1764207236\n"
     ]
    }
   ],
   "source": [
    "# Save into s3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "file_path = '/tmp/output.parquet'\n",
    "df.to_parquet(file_path, index=False)\n",
    "bucket_folder_output = f'{folder_out_zone}/output.parquet'\n",
    "s3.meta.client.upload_file(file_path, bucket_name_dl, bucket_folder_output)\n",
    "\n",
    "# Create Url to download outsite aws\n",
    "url = s3_client.generate_presigned_url(\n",
    "    'get_object',\n",
    "    Params={'Bucket': bucket_name_dl, 'Key': bucket_folder_output},\n",
    "    ExpiresIn=60 * 60 * 24 * 15  # 1 hour\n",
    ")\n",
    "\n",
    "print(\"Download link:\", url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
